# Takes the path to an extracted benchmark run which contains CSV files for each source/category.
# Parses them and plots them into a cumulative stacked chart.
# Parses the slurm.out file and prints I/O for each phase.

import argparse
import datetime as dt
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import sys

# get the benchmark's directory containing all files
parser = argparse.ArgumentParser()
parser.add_argument("bd", help="path to the benchmark directory")
args = parser.parse_args()

# read all CSV files into one DataFrame
raw_data = pd.DataFrame()
files = os.listdir(args.bd)
slurm_file = None
for f in files:
    if ('sfs' in f or 'jvm' in f) and f.endswith('csv'):
        print("Reading {} ...".format(f))
        raw_data = raw_data.append(pd.read_csv(args.bd + '/' + f)).fillna(0)
    elif 'slurm' in f and f.endswith('out'):
        print("Reading {} ...".format(f))
        slurm_file = args.bd + '/' + f

if slurm_file is None:
    raise Exception('No slurm.out file found')

# parse start and end times from the log file, as well as interesting I/O
stats = dict()
with open(slurm_file) as f:
    for line in f:
        # removes leading spaces and trailing newline
        line = line.strip()

        # messages generated by us, extract start and end time for TeraGen/TeraSort from them
        if line.endswith(": Generating TeraSort data on HDFS"):
            date = line[:-len(": Generating TeraSort data on HDFS")].replace("  ", " ")
            stats['teragen.time.start'] = dt.datetime.strptime(date, "%a %b %d %H:%M:%S %Z %Y").timestamp() 
        elif line.endswith(": Generating TeraSort data on HDFS done"):
            date = date = line[:-len(": Generating TeraSort data on HDFS done")].replace("  ", " ")
            stats['teragen.time.end'] = dt.datetime.strptime(date, "%a %b %d %H:%M:%S %Z %Y").timestamp()
        elif line.endswith(": Running TeraSort"):
            date = line[:-len(": Running TeraSort")].replace("  ", " ")
            stats['terasort.time.start'] = dt.datetime.strptime(date, "%a %b %d %H:%M:%S %Z %Y").timestamp()
        elif line.endswith(": Running TeraSort done: 0"):
            date = line[:-len(": Running TeraSort done: 0")].replace("  ", " ")
            stats['terasort.time.end'] = dt.datetime.strptime(date, "%a %b %d %H:%M:%S %Z %Y").timestamp()
        # MapReduce framework counters
        elif line.startswith("HDFS: Number of bytes read="):
            # first encounter is TeraGen
            if stats.get('teragen.io.hdfs.read', None) == None:
                stats['teragen.io.hdfs.read'] = int(line.split("=")[1])
            # second encounter is TeraSort
            elif stats.get('terasort.io.hdfs.read', None) == None:
                stats['terasort.io.hdfs.read'] = int(line.split("=")[1])
        elif line.startswith("HDFS: Number of bytes written="):
            if stats.get('teragen.io.hdfs.write', None) == None:
                stats['teragen.io.hdfs.write'] = int(line.split("=")[1])
            elif stats.get('terasort.io.hdfs.write', None) == None:
                stats['terasort.io.hdfs.write'] = int(line.split("=")[1])
        elif line.startswith("FILE: Number of bytes read="):
            if stats.get('teragen.io.file.read', None) == None:
                stats['teragen.io.file.read'] = int(line.split("=")[1])
            elif stats.get('terasort.io.file.read', None) == None:
                stats['terasort.io.file.read'] = int(line.split("=")[1])
        elif line.startswith("FILE: Number of bytes written="):
            if stats.get('teragen.io.file.write', None) == None:
                stats['teragen.io.file.write'] = int(line.split("=")[1])
            elif stats.get('terasort.io.file.write', None) == None:
                stats['terasort.io.file.write'] = int(line.split("=")[1])
        elif line.startswith("Reduce shuffle bytes="):
            stats['terasort.io.shuffle.read'] = int(line.split("=")[1])
        elif line.startswith("Map output materialized bytes="):
            stats['terasort.io.shuffle.write'] = int(line.split("=")[1])
        elif line.startswith("Spilled Records="):
            if stats.get('teragen.io.spill', None) == None:
                stats['teragen.io.spill'] = int(line.split("=")[1])
            elif stats.get('terasort.io.spill', None) == None:
                stats['terasort.io.spill'] = int(line.split("=")[1])

# use beginning of TeraGen as zero
stats['terasort.time.end']   -= stats['teragen.time.start']
stats['terasort.time.start'] -= stats['teragen.time.start']
stats['teragen.time.end']    -= stats['teragen.time.start']
stats['teragen.time.start']   = 0

# read XFS and ext4 statistics as well
mounts = {
    'xfs'  : { 'all' },
    'ext4' : set()
}
for f in files:
    # file name is <jobid>-<hostname>.<filesystem>.<mount>.<phase>
      # e.g. 1234-cumu02-00.xfs.local.mid
    if 'xfs' in f:
        parts = f.split(".")
        mount = parts[2]
        mounts['xfs'].add(mount)
        phase = parts[3]
        with open(args.bd + '/' + f) as lines:
            for line in lines:
                if line.startswith("xpc"):
                    # xpc <xs_xstrat_bytes> <xs_write_bytes> <xs_read_bytes>
                    xpc = line.split(" ")

                    # add artificial mount that receives all I/O as aggregate
                    for m in [mount, 'all']:
                        if phase == 'pre':
                            stats['teragen.io.xfs.'  + m +  '.read'] = stats.get('teragen.io.xfs.'  + m +  '.read', 0) - int(xpc[3])
                            stats['teragen.io.xfs.'  + m + '.write'] = stats.get('teragen.io.xfs.'  + m + '.write', 0) - int(xpc[2])
                        elif phase == 'mid':
                            stats['teragen.io.xfs.'  + m +  '.read'] = stats.get('teragen.io.xfs.'  + m +  '.read', 0) + int(xpc[3])
                            stats['teragen.io.xfs.'  + m + '.write'] = stats.get('teragen.io.xfs.'  + m + '.write', 0) + int(xpc[2])
                            stats['terasort.io.xfs.' + m +  '.read'] = stats.get('terasort.io.xfs.' + m +  '.read', 0) - int(xpc[3])
                            stats['terasort.io.xfs.' + m + '.write'] = stats.get('terasort.io.xfs.' + m + '.write', 0) - int(xpc[2])
                        elif phase == 'post':
                            stats['terasort.io.xfs.' + m +  '.read'] = stats.get('terasort.io.xfs.' + m +  '.read', 0) + int(xpc[3])
                            stats['terasort.io.xfs.' + m + '.write'] = stats.get('terasort.io.xfs.' + m + '.write', 0) + int(xpc[2])
    elif 'ext4' in f:
        parts = f.split(".")
        mount = parts[2]
        mounts['ext4'].add(mount)
        phase = parts[3]
        with open(args.bd + '/' + f) as lines:
            # just one line with writes in kilobytes
            w = lines.readline()
            for m in [mount, 'all']:
                if phase == 'pre':
                    stats['teragen.io.ext4.'  + m + '.write'] = stats.get('teragen.io.ext4.'  + m + '.write', 0) - int(w)
                elif phase == 'mid':
                    stats['teragen.io.ext4.'  + m + '.write'] = stats.get('teragen.io.ext4.'  + m + '.write', 0) + int(w)
                    stats['terasort.io.ext4.' + m + '.write'] = stats.get('terasort.io.ext4.' + m + '.write', 0) - int(w)
                elif phase == 'post':
                    stats['terasort.io.ext4.' + m + '.write'] = stats.get('terasort.io.ext4.' + m + '.write', 0) + int(w)

# print stats
print("")

# figure out longest file system + mount point name to align all output
max_mount_length = 0
for fs in ['xfs', 'ext4']:
    for mount in mounts[fs]:
        max_mount_length = max(max_mount_length, len(mount) + len(fs))

# maximum line length before the value is printed
# max_mount_length
#   +1 space in between file system and mount point
#   +1 space after the mount point
#   +7 for "Write: "
max_line_length = max_mount_length + 9
def rpad(s):
    return '{0: <{1}}'.format(s, max_line_length)

print("TeraGen")
print("=======")
print(rpad("Duration:")   + "{} minutes".format(int(round((stats['teragen.time.end'] - stats['teragen.time.start']) / 60.0))))
print(rpad("HDFS Read:")  + "{} GiB".format(int(round(stats['teragen.io.hdfs.read']     / 1073741824.0))))
print(rpad("HDFS Write:") + "{} GiB".format(int(round(stats['teragen.io.hdfs.write']    / 1073741824.0))))
print(rpad("FILE Read:")  + "{} GiB".format(int(round(stats['teragen.io.file.read']     / 1073741824.0))))
print(rpad("FILE Write:") + "{} GiB".format(int(round(stats['teragen.io.file.write']    / 1073741824.0))))
print(rpad("Spill:")      + "{} GiB".format(int(round(stats['teragen.io.spill'] * 100.0 / 1073741824.0))))
for mount in sorted(mounts['xfs']):
    print(rpad("XFS {} Read:".format(mount))   + "{} GiB".format(int(round(stats['teragen.io.xfs.'  + mount +  '.read'] / 1073741824.0))))
    print(rpad("XFS {} Write:".format(mount))  + "{} GiB".format(int(round(stats['teragen.io.xfs.'  + mount + '.write'] / 1073741824.0))))
for mount in sorted(mounts['ext4']):
    print(rpad("ext4 {} Write:".format(mount)) + "{} GiB".format(int(round(stats['teragen.io.ext4.' + mount + '.write'] / 1048576.0))))

print("")

print("TeraSort")
print("=======")
print(rpad("Duration:")      + "{} minutes".format(int(round((stats['terasort.time.end'] - stats['terasort.time.start']) / 60.0))))
print(rpad("HDFS Read:")     + "{} GiB".format(int(round(stats['terasort.io.hdfs.read']     / 1073741824.0))))
print(rpad("HDFS Write:")    + "{} GiB".format(int(round(stats['terasort.io.hdfs.write']    / 1073741824.0))))
print(rpad("FILE Read:")     + "{} GiB".format(int(round(stats['terasort.io.file.read']     / 1073741824.0))))
print(rpad("FILE Write:")    + "{} GiB".format(int(round(stats['terasort.io.file.write']    / 1073741824.0))))
print(rpad("Shuffle Read:")  + "{} GiB".format(int(round(stats['terasort.io.shuffle.read']  / 1073741824.0))))
print(rpad("Shuffle Write:") + "{} GiB".format(int(round(stats['terasort.io.shuffle.write'] / 1073741824.0))))
print(rpad("Spill:")         + "{} GiB".format(int(round(stats['terasort.io.spill'] * 100.0 / 1073741824.0))))
for mount in sorted(mounts['xfs']):
    print(rpad("XFS {} Read:".format(mount))   + "{} GiB".format(int(round(stats['terasort.io.xfs.'  + mount +  '.read'] / 1073741824.0))))
    print(rpad("XFS {} Write:".format(mount))  + "{} GiB".format(int(round(stats['terasort.io.xfs.'  + mount + '.write'] / 1073741824.0))))
for mount in sorted(mounts['ext4']):
    print(rpad("ext4 {} Write:".format(mount)) + "{} GiB".format(int(round(stats['terasort.io.ext4.' + mount + '.write'] / 1048576.0))))

print("")

print("Total")
print("=====")
print(rpad("Duration:")      + "{} minutes".format(int(round((stats['teragen.time.end'] - stats['teragen.time.start'] + stats['terasort.time.end'] - stats['terasort.time.start']) / 60.0))))
print(rpad("HDFS Read:")     + "{} GiB".format(int(round((stats['teragen.io.hdfs.read']  + stats['terasort.io.hdfs.read'])     / 1073741824.0))))
print(rpad("HDFS Write:")    + "{} GiB".format(int(round((stats['teragen.io.hdfs.write'] + stats['terasort.io.hdfs.write'])    / 1073741824.0))))
print(rpad("FILE Read:")     + "{} GiB".format(int(round((stats['teragen.io.file.read']  + stats['terasort.io.file.read'])     / 1073741824.0))))
print(rpad("FILE Write:")    + "{} GiB".format(int(round((stats['teragen.io.file.write'] + stats['terasort.io.file.write'])    / 1073741824.0))))
print(rpad("Shuffle Read:")  + "{} GiB".format(int(round((stats['terasort.io.shuffle.read'])                                   / 1073741824.0))))
print(rpad("Shuffle Write:") + "{} GiB".format(int(round((stats['terasort.io.shuffle.write'])                                  / 1073741824.0))))
print(rpad("Spill:")         + "{} GiB".format(int(round((stats['teragen.io.spill']      + stats['terasort.io.spill']) * 100.0 / 1073741824.0))))
for mount in sorted(mounts['xfs']):
    print(rpad("XFS {} Read:".format(mount))   + "{} GiB".format(int(round((stats['teragen.io.xfs.'  + mount +  '.read'] + stats['terasort.io.xfs.' + mount +  '.read']) / 1073741824.0))))
    print(rpad("XFS {} Write:".format(mount))  + "{} GiB".format(int(round((stats['teragen.io.xfs.'  + mount + '.write'] + stats['terasort.io.xfs.' + mount + '.write']) / 1073741824.0))))
for mount in sorted(mounts['ext4']):
    print(rpad("ext4 {} Write:".format(mount)) + "{} GiB".format(int(round((stats['teragen.io.ext4.' + mount + '.write'] + stats['terasort.io.ext4.' + mount + '.write']) / 1048576.0))))

print("")

if raw_data.empty:
    print("No CSV data imported, exiting.")
    quit()

# aggregate over all pids of desired hosts the metrics per time, key, source and category
hostnames = [
    'cumu01-00',
    'cumu01-01',
    'cumu01-02',
    'cumu01-03',
    'cumu01-04',
    'cumu01-05',
    'cumu01-06',
    'cumu01-07',
    'cumu01-08',
    'cumu01-09',
    'cumu01-10',
    'cumu01-11',
    'cumu01-12',
    'cumu01-13',
    'cumu01-14',
    'cumu01-15',
    'cumu02-00',
    'cumu02-01',
    'cumu02-02',
    'cumu02-03',
    'cumu02-04',
    'cumu02-05',
    'cumu02-06',
    'cumu02-07',
    'cumu02-08',
    'cumu02-09',
    'cumu02-10',
    'cumu02-11',
    'cumu02-12',
    'cumu02-13',
    'cumu02-14',
    'cumu02-15'
]
grouped_data = raw_data[raw_data['hostname'].isin(hostnames)].drop(['hostname', 'pid', 'fileDescriptor'], axis=1).groupby(['timeBin', 'key', 'source', 'category'], as_index=False).sum().set_index(['timeBin'], drop=False)

# regroup to obtain a DataFrame per key/source/category tuple
current_data = grouped_data.groupby(['key', 'source', 'category'], as_index=False)

# orders of plots when plotting SFS
sfs_orders = {
    ('map', 'sfs', 'write')    : 0,
    ('map', 'sfs', 'read')     : 1,
    ('reduce', 'sfs', 'write') : 2,
    ('reduce', 'sfs', 'read')  : 3,
    ('flink', 'sfs', 'write')  : 4,
    ('flink', 'sfs', 'read')   : 5
}

# orders of plots when plotting JVM
jvm_orders = {
    ('yarn', 'jvm', 'write')   : 0,
    ('yarn', 'jvm', 'read')    : 1,
    ('hdfs', 'jvm', 'write')   : 2,
    ('hdfs', 'jvm', 'read')    : 3,
    ('map', 'jvm', 'write')    : 4,
    ('map', 'jvm', 'read')     : 5,
    ('reduce', 'jvm', 'write') : 6,
    ('reduce', 'jvm', 'read')  : 7,
    ('flink', 'jvm', 'write')  : 8,
    ('flink', 'jvm', 'read')   : 9
}

for orders in [jvm_orders, sfs_orders]:
    # loop over all unique groups to build global index
    plot_index = None
    for group, group_data in current_data:
        plot_index = group_data.index if plot_index is None else plot_index.union(group_data.index)

    # dataframe used for plotting
    plot_data = pd.DataFrame(index=plot_index)
        
    # loop over all unique groups in previously defined order
    for group in sorted([g for g in current_data.groups if g in orders], key=lambda g: orders[g]):
        # group[0] contains the key, e.g. hadoop, spark, yarn, ...
        # group[1] contains jvm or sfs
        # group[2] contains read, write or other
        
        # get this group's data
        group_data = current_data.get_group(group)

        plot_data = plot_data.assign(**{ "{}: {}".format(group[0].capitalize(), group[2].capitalize()) : group_data['data'].cumsum() / 1073741824.0 })

    # compute the minute value for each time bin so we can plot against it
    plot_data = plot_data.assign(Minutes=lambda x: (x.index - plot_index.values[0]) / 60000)
    plot_data = plot_data.fillna(method='pad')

    plt.style.use('ggplot')
    plt.clf()

    ax = plot_data.plot.area(
        figsize=(32, 16),
        title="TeraSort I/O",
        legend=False,
        grid=False,
        x='Minutes',      # use computed minutes as x ticks
        linewidth=0       # to not show the line where the cumulative sum is still 0
    )
    patches, labels = ax.get_legend_handles_labels()
    ax.legend(reversed(patches), reversed(labels), loc='best') # reverse because we have added the plots bottom-up
    ax.set_ylabel("Stacked Cumulative Data (GiB)")
    ax2 = ax.twinx()
    ax2.set_ylim(ax.get_ylim())
    ax2.set_ylabel("Stacked Cumulative Data (GiB)")

    # add annotations, bottom to top
    yfrac = 1.0 / (plot_data.shape[1] - 1)
    i = 0
    total_data = 0
    for column in plot_data:
        if column == 'Minutes':
            continue

        total_data = total_data + plot_data[column].iloc[-1]
        ax.annotate(
            "{}: {} GiB".format(column, (int) (round(plot_data[column].iloc[-1]))),
            xy=(plot_data['Minutes'].iloc[-1], total_data), xycoords='data',
            xytext=(.975, .5 / (plot_data.shape[1] - 1) + i * yfrac), textcoords='axes fraction',
            size=20, va="center", ha="right",
            bbox=dict(boxstyle="round", fc="w", ec="0.5"),
            arrowprops=dict(arrowstyle="fancy", fc="w", ec="0.5")
        )
        i += 1
        
    # indicate teragen and terasort
    teragen_terasort_border = stats['teragen.time.end'] + (stats['terasort.time.start'] - stats['teragen.time.end']) / 2.0
    ax.annotate("",
        xy=(teragen_terasort_border / 60.0, 0), xycoords='data',
        xytext=(teragen_terasort_border / 60.0, total_data), textcoords='data',
        arrowprops=dict(arrowstyle="-", linewidth=4),
    )
    ax.text((teragen_terasort_border - 180.0) / 60.0, .75 * total_data, "TeraGen", ha="right", va="center", size=20,
            bbox=dict(boxstyle="rarrow", fc="w", ec="0.5", alpha=0.9))
    ax.text((teragen_terasort_border + 180.0) / 60.0, .75 * total_data, "TeraSort", ha="left", va="center", size=20,
            bbox=dict(boxstyle="rarrow", fc="w", ec="0.5", alpha=0.9))
        
    plt.savefig(args.bd + "/terasort-io-{}.pdf".format(dt.datetime.now()))
